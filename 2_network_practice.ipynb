{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Group information**\n",
    "\n",
    "| Family name | First name | Email address |\n",
    "| ----------- | ---------- | ------------- |\n",
    "|             |            |               |\n",
    "|             |            |               |\n",
    "|             |            |               |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network - Practice\n",
    "\n",
    "This tutorial explores how to implement a simple neural network to predict the likelihood of loan default from borrower loan characteristics. The labelled dataset contains 100,000 observations and 16 predictors (e.g. income, credit score). The response is a binary variable indicating whether the borrower defaulted on the loan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import inspect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from sklearn import metrics, model_selection, preprocessing\n",
    "from tensorflow.keras import callbacks, layers, losses, models, optimizers, regularizers\n",
    "from urllib import request\n",
    "\n",
    "# Utilities\n",
    "os.chdir(f\"{os.path.expanduser('~')}/Desktop\")\n",
    "\n",
    "def download_data():\n",
    "    '''Downloads data folder'''\n",
    "    request.urlretrieve('https://www.dropbox.com/scl/fo/enlhq3he4vrxtsw9goup5/AB5uNqD0dwdTG2fO8orV02U?rlkey=oan5la71do06r0gpe5ea5ii5b&dl=1', 'data.zip')\n",
    "    shutil.unpack_archive('data.zip', 'data')\n",
    "    os.remove('data.zip')\n",
    "    os.chdir('data')\n",
    "\n",
    "def plot_history(history, metric='loss', validation=False):\n",
    "    '''Plots the training history for a given metric'''\n",
    "    fig, ax = pyplot.subplots(1, figsize=(5,5))\n",
    "    ax.plot(history[metric], label=f'Validation {metric}')\n",
    "    if validation:\n",
    "        ax.plot(history[f'val_{metric}'], label=f'Validation {metric}')\n",
    "    ax.set_title(f'Model {metric}')\n",
    "    ax.set_ylabel(metric.title())\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.legend(['Training', 'Validation'])\n",
    "    pyplot.tight_layout()\n",
    "    pyplot.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the `X` and `y` datasets and produce some descriptive statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads data\n",
    "download_data() # On first run\n",
    "X = pd.read_csv('X.csv', index_col='loan_id')\n",
    "y = pd.read_csv('y.csv', index_col='loan_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Pre-process the data by encoding the categorical variables using dummies (see `pd.get_dummies`) and formatting the default variable as probabilities (i.e. `float`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Split the dataset into a training and a test sample (see `model_selection.train_test_split`) and allocate 80% of the observations to the training sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Scale the input variables (see `preprocessing.MinMaxScaler`) by fitting the scaler on the training sample and applying the transformation to both the training and the test sample. Explain why input scaling is required for machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Using the `keras` [functional API](https://keras.io/guides/functional_api/), define a network model structure with an input [layer](https://keras.io/api/layers/core_layers/), two dense hidden layers containing 16 units each and ReLU [activation](https://keras.io/api/layers/activations/), as well as an output layer with a single unit and the appropriate activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Intialise an instance of the model and call the `summary` method to visualise the model structure, explain the number of parameters for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. [Compile](https://keras.io/api/models/model_training_apis/) the model and specify an appropriate [loss function](https://keras.io/api/losses/) and [optimisation algorithm](https://keras.io/api/optimizers/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. [Fit](https://keras.io/api/models/model_training_apis/) the model to the training data. Use a batch size of 64 and a maximum of 5 epoch. Plot the training history using the provided function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. [Evaluate](https://keras.io/api/models/model_training_apis/) the model on the test sample and display a confusion matrix (see `metrics.confusion_matrix`) for the test sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Apply [regularisation](https://keras.io/api/layers/regularizers/) to the parameters in the hidden layers and improve the generalisation performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Modify the model structure to improve predictive performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7302c24fb2197c6d308d8a799b8c1926c619b1d29b7e68a60c06bc7e0374fe3f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
